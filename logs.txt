INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.compaction_ctrl_update_interval_ms:30000      - 
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.controller_backend_housekeeping_interval_ms:1000      - Interval between iterations of controller backend housekeeping loop
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.controller_log_accummulation_rps_capacity_acls_and_users_operations:{nullopt}   - Maximum capacity of rate limit accumulationin controller acls and users operations limit
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.controller_log_accummulation_rps_capacity_configuration_operations:{nullopt}    - Maximum capacity of rate limit accumulationin controller configuration operations limit
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.controller_log_accummulation_rps_capacity_move_operations:{nullopt}     - Maximum capacity of rate limit accumulationin controller move operations limit
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.controller_log_accummulation_rps_capacity_node_management_operations:{nullopt}  - Maximum capacity of rate limit accumulationin controller node management operations limit
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.controller_log_accummulation_rps_capacity_topic_operations:{nullopt}    - Maximum capacity of rate limit accumulationin controller topic operations limit
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.controller_snapshot_max_age_sec:60000 - Max time that will pass before we make an attempt to create a controller snapshot, after a new controller command appears
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.coproc_max_batch_size:        - 
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.coproc_max_inflight_bytes:    - 
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.coproc_max_ingest_bytes:      - 
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.coproc_offset_flush_interval_ms:      - 
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.core_balancing_continuous:0   - If set to 'true', move partitions between cores in runtime to maintain balanced partition distribution.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.core_balancing_debounce_timeout:10000 - Interval, in milliseconds, between trigger and invocation of core balancing.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.core_balancing_on_core_count_change:1 - If set to 'true', and if after a restart the number of cores changes, Redpanda will move partitions between cores to maintain balanced partition distribution.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.cpu_profiler_enabled:0        - Enables cpu profiling for Redpanda
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.cpu_profiler_sample_period_ms:100     - The sample period for the CPU profiler
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.create_topic_timeout_ms:2000  - Timeout (ms) to wait for new topic creation
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.data_transforms_binary_max_size:10485760      - The maximum size for a deployable WebAssembly binary that the broker can store.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.data_transforms_commit_interval_ms:3000       - The interval at which Data Transforms commits progress.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.data_transforms_enabled:0     - Enables WebAssembly powered Data Transforms directly in the broker
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.data_transforms_logging_buffer_capacity_bytes:512000  - Buffer capacity for transform logs, per shard. Buffer occupancy is calculated as the total size of buffered (i.e. emitted but not yet produced) log messages.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.data_transforms_logging_flush_interval_ms:500 - Flush interval for transform logs. When a timer expires, pending logs are collected and published to the transform_logs topic.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.data_transforms_logging_line_max_bytes:1024   - Transform log lines will be truncate to this length. Truncation occurs after any character escaping.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.data_transforms_per_core_memory_reservation:20971520  - The amount of memory to reserve per core for Data Transform WebAssembly Virtual Machines. Memory is reserved on boot. The maximum number of functions that can be deployed to a cluster is equal to data_transforms_per_core_memory_reservation / data_transforms_per_function_memory_limit
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.data_transforms_per_function_memory_limit:2097152     - The amount of memory to give an instance of a Data Transform WebAssembly Virtual Machine. The maximum number of functions that can be deployed to a cluster is equal to data_transforms_per_core_memory_reservation / data_transforms_per_function_memory_limit
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.data_transforms_read_buffer_memory_percentage:45      - The percentage of available memory in the transform subsystem to use for read buffers
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.data_transforms_runtime_limit_ms:3000 - The maximum amount of runtime for startup time of a data transform, and the time it takes for a single record to be transformed.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.data_transforms_write_buffer_memory_percentage:45     - The percentage of available memory in the transform subsystem to use for write buffers
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.debug_load_slice_warning_depth:{nullopt}      - The recursion depth after which debug logging will be enabled automatically for the log reader.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.default_num_windows:10        - Default number of quota tracking windows
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.default_topic_partitions:1    - Default number of partitions per topic
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.default_topic_replications:1  - Default replication factor for new topics
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.default_window_sec:1000       - Default quota tracking window size in milliseconds
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.disable_batch_cache:0 - Disable batch cache in log manager
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.disable_cluster_recovery_loop_for_tests:0     - Disables the cluster recovery loop. The property exists to simplify testing and shouldn't be set in production.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.disable_metrics:0     - Disable registering metrics exposed on the internal metrics endpoint (/metrics)
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.disable_public_metrics:0      - Disable registering metrics exposed on the public metrics endpoint (/public_metrics)
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.disk_reservation_percent:25   - The percentage of total disk capacity that Redpanda will avoid using. This applies both when cloud cache and log data share a disk, as well as when cloud cache uses a dedicated disk. It is recommended to not run disks near capacity to avoid blocking I/O due to low disk space, as well as avoiding performance issues associated with SSD garbage collection.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.election_timeout_ms:1500      - Election timeout expressed in milliseconds
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.enable_admin_api:     - 
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.enable_auto_rebalance_on_node_add:0   - Enable automatic partition rebalancing when new nodes are added
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.enable_cluster_metadata_upload_loop:1 - Enables the cluster metadata upload loop.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.enable_controller_log_rate_limiting:0 - Enables limiting of controller log write rate
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.enable_coproc:        - 
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.enable_idempotence:1  - Enable idempotent producer
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.enable_leader_balancer:1      - Enable automatic leadership rebalancing
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.enable_metrics_reporter:1     - Enable cluster metrics reporter
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.enable_mpx_extensions:0       - Enable Redpanda extensions for MPX.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.enable_pid_file:1     - Enable pid file. You probably don't want to change this.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.enable_rack_awareness:0       - Enables rack-aware replica assignment
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.enable_sasl:0 - Enable SASL authentication for Kafka connections, authorization is required. see also `kafka_enable_authorization`
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.enable_schema_id_validation:none      - Enable Server Side Schema ID Validation.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.enable_transactions:1 - Enable transactions
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.enable_usage:0        - Enables the usage tracking mechanism, storing windowed history of kafka/cloud_storage metrics over time
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.features_auto_enable:1        - Whether new feature flags may auto-activate after upgrades (true) or must wait for manual activation via the admin API (false)
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.fetch_max_bytes:57671680      - Maximum number of bytes returned in fetch request
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.fetch_read_strategy:non_polling       - The strategy used to fulfill fetch requests
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.fetch_reads_debounce_timeout:10       - Time to wait for next read in fetch request when requested min bytes wasn't reached
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.fetch_session_eviction_timeout_ms:60000       - Minimum time before which unused session will get evicted from sessions. Maximum time after which inactive session will be deleted is two time given configuration valuecache
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.find_coordinator_timeout_ms:2000      - Time to wait for a response from tx_registry
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.full_raft_configuration_recovery_pattern:     - 
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.group_initial_rebalance_delay:0       - Extra delay (ms) added to rebalance phase to wait for new members
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.group_max_session_timeout_ms:300000   - The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures. 
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.group_min_session_timeout_ms:6000     - The minimum allowed session timeout for registered consumers. Shorter timeouts result in quicker failure detection at the cost of more frequent consumer heartbeating, which can overwhelm broker resources.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.group_new_member_join_timeout:30000   - Timeout for new member joins
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.group_offset_retention_check_ms:600000        - How often the system should check for expired group offsets.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.group_offset_retention_sec:{604800000}        - Consumer group offset retention seconds. Offset retention can be disabled by setting this value to null.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.group_topic_partitions:3      - Number of partitions in the internal group membership topic
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.health_manager_tick_interval:180000   - How often the health manager runs
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.health_monitor_max_metadata_age:10000 - Max age of metadata cached in the health monitor of non controller node
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.health_monitor_tick_interval:10000    - How often health monitor refresh cluster state
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.http_authentication:{BASIC}   - A list of supported HTTP authentication mechanisms. `BASIC` and `OIDC` are allowed.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.id_allocator_batch_size:1000  - Id allocator allocates messages in batches (each batch is a one log record) and then serves requests from memory without touching the log until the batch is exhausted.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.id_allocator_log_capacity:100 - Capacity of the id_allocator log in number of batches. Once it reached id_allocator_stm truncates log's prefix.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.id_allocator_replication:     - 
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.initial_retention_local_target_bytes_default:{nullopt}        - Initial local retention size target for partitions of topics with cloud storage write enabled. If no initial local target retention is configured all locally retained data will be delivered to learner when joining partition replica set
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.initial_retention_local_target_ms_default:{nullopt}   - Initial local retention time target for partitions of topics with cloud storage write enabled. If no initial local target retention is configured all locally retained data will be delivered to learner when joining partition replica set
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.internal_topic_replication_factor:3   - Target replication factor for internal topics
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.join_retry_timeout_ms:5000    - Time between cluster join retries in milliseconds
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_admin_topic_api_rate:{nullopt}  - Target quota rate (partition mutations per default_window_sec)
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_batch_max_bytes:1048576 - Maximum size of a batch processed by server. If batch is compressed the limit applies to compressed batch size
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_client_group_byte_rate_quota:{} - Per-group target produce quota byte rate (bytes per second). Client is considered part of the group if client_id contains clients_prefix
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_client_group_fetch_byte_rate_quota:{}   - Per-group target fetch quota byte rate (bytes per second). Client is considered part of the group if client_id contains clients_prefix
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_connection_rate_limit:{nullopt} - Maximum connections per second for one core
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_connection_rate_limit_overrides:{}      - Overrides for specific ips for maximum connections per second for one core
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_connections_max:{nullopt}       - Maximum number of Kafka client connections per broker
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_connections_max_overrides:{}    - Per-IP overrides of kafka connection count limit, list of <ip>:<count> strings
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_connections_max_per_ip:{nullopt}        - Maximum number of Kafka client connections from each IP address, per broker
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_enable_authorization:{nullopt}  - Enable authorization for Kafka connections. Values:- `nil`: Ignored. Authorization is enabled with `enable_sasl: true`; `true`: authorization is required; `false`: authorization is disabled. See also: `enable_sasl` and `kafka_api[].authentication_method`
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_enable_describe_log_dirs_remote_storage:1       - Whether to include tiered storage as a special remote:// directory in DescribeLogDirs Kafka API requests.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_enable_partition_reassignment:1 - Enable the Kafka partition reassignment API
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_group_recovery_timeout_ms:30000 - Kafka group recovery timeout expressed in milliseconds
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_max_bytes_per_fetch:67108864    - Limit fetch responses to this many bytes, even if total of partition bytes limits is higher
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_memory_batch_size_estimate_for_fetch:1048576    - The size of the batch used to estimate memory consumption for Fetch requests, in bytes. Smaller sizes allow more concurrent fetch requests per shard, larger sizes prevent running out of memory because of too many concurrent fetch requests.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_memory_share_for_fetch:0.5      - The share of kafka subsystem memory that can be used for fetch read buffers, as a fraction of kafka subsystem memory amount
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_mtls_principal_mapping_rules:{nullopt}  - Principal Mapping Rules for mTLS Authentication on the Kafka API
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_nodelete_topics:{_redpanda.audit_log, __consumer_offsets, _schemas}       - Prevents the topics in the list from being deleted via the kafka api
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_noproduce_topics:{}     - Prevents the topics in the list from having message produced to them via the kafka api
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_qdc_depth_alpha:0.8     - Smoothing factor for kafka queue depth control depth tracking.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_qdc_depth_update_ms:7000        - Update frequency for kafka queue depth control.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_qdc_enable:0    - Enable kafka queue depth control.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_qdc_idle_depth:10       - Queue depth when idleness is detected in kafka queue depth control.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_qdc_latency_alpha:0.002 - Smoothing parameter for kafka queue depth control latency tracking.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_qdc_max_depth:100       - Maximum queue depth used in kafka queue depth control.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_qdc_max_latency_ms:80   - Max latency threshold for kafka queue depth control depth tracking.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_qdc_min_depth:1 - Minimum queue depth used in kafka queue depth control.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_qdc_window_count:12     - Number of windows used in kafka queue depth control latency tracking.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_qdc_window_size_ms:1500 - Window size for kafka queue depth control latency tracking.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_quota_balancer_min_shard_throughput_bps:256     - The lowest value of the throughput quota a shard can get in the process of quota balancing, in bytes/s. 0 means there is no minimum.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_quota_balancer_min_shard_throughput_ratio:0.01  - The lowest value of the throughput quota a shard can get in the process of quota balancing, expressed as a ratio of default shard quota. 0 means there is no minimum, 1 means no quota can be taken away by the balancer.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_quota_balancer_node_period_ms:0 - Intra-node throughput quota balancer invocation period, in milliseconds. Value of 0 disables the balancer and makes all the throughput quotas immutable.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_quota_balancer_window_ms:5000   - Time window used to average current throughput measurement for quota balancer, in milliseconds
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_request_max_bytes:104857600     - Maximum size of a single request processed via Kafka API
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_rpc_server_stream_recv_buf:{nullopt}    - Userspace receive buffer max size in bytes
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_rpc_server_tcp_recv_buf:{nullopt}       - Kafka server TCP receive buffer size in bytes.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_rpc_server_tcp_send_buf:{nullopt}       - Kafka server TCP transmit buffer size in bytes.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_sasl_max_reauth_ms:{nullopt}    - The maximum time between Kafka client reauthentications. If a client has not reauthenticated a connection within this time frame, that connection is torn down. Without this, a connection could live long after the client's credentials are expired or revoked. Session expiry is disabled if the value is null.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_schema_id_validation_cache_capacity:128 - Per-shard capacity of the cache for validating schema IDs.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_tcp_keepalive_probe_interval_seconds:60000      - TCP keepalive probe interval in seconds for kafka connections. This describes the timeout between unacknowledged tcp keepalives. Refers to the TCP_KEEPINTVL socket option. When changed applies to new connections only.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_tcp_keepalive_probes:3  - TCP keepalive unacknowledged probes until the connection is considered dead for kafka connections. Refers to the TCP_KEEPCNT socket option. When changed applies to new connections only.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_tcp_keepalive_timeout:120000    - TCP keepalive idle timeout in seconds for kafka connections. This describes the timeout between tcp keepalive probes that the remote sitesuccessfully acknowledged. Refers to the TCP_KEEPIDLE socket option. When changed applies to new connections only.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_throughput_control:{}   - List of throughput control groups that define exclusions from node-wide throughput limits. Each group consists of: ("name" (optional) - any unique group name, "client_id" - regex to match client_id). A connection is assigned the first matching group, then the connection is excluded from throughput control.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_throughput_controlled_api_keys:{produce, fetch} - List of Kafka API keys that are subject to cluster-wide and node-wide throughput limit control
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_throughput_limit_node_in_bps:{nullopt}  - Node wide throughput ingress limit - maximum kafka traffic throughput allowed on the ingress side of each node, in bytes/s. Default is no limit.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_throughput_limit_node_out_bps:{nullopt} - Node wide throughput egress limit - maximum kafka traffic throughput allowed on the egress side of each node, in bytes/s. Default is no limit.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_throughput_replenish_threshold:{nullopt}        - Threshold for refilling the token bucket. Will be clamped between 1 and kafka_throughput_limit_node_*_bps.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kafka_throughput_throttling_v2:1      - Use throughput throttling based on a shared token bucket instead of balancing quota between shards
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kvstore_flush_interval:10     - Key-value store flush interval (ms)
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.kvstore_max_segment_size:16777216     - Key-value maximum segment size (bytes)
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.leader_balancer_idle_timeout:120000   - Leadership rebalancing idle timeout
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.leader_balancer_mode:random_hill_climbing     - Leader balancer mode
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.leader_balancer_mute_timeout:300000   - Leadership rebalancing mute timeout
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.leader_balancer_transfer_limit_per_shard:512  - Per shard limit for in progress leadership transfers
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.legacy_group_offset_retention_enabled:0       - Group offset retention is enabled by default in versions of Redpanda >= 23.1. To enable offset retention after upgrading from an older version set this option to true.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.legacy_permit_unsafe_log_operation:1  - Permits the use of strings that may induct log injection/modification
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.legacy_unsafe_log_warning_interval_sec:300000 - Interval, in seconds, of how often a message informing the operator that unsafe strings are permitted
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.log_cleanup_policy:delete     - Default topic cleanup policy
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.log_compaction_interval_ms:10000      - How often do we trigger background compaction
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.log_compaction_use_sliding_window:1   - Use sliding window compaction.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.log_compression_type:producer - Default topic compression type
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.log_disable_housekeeping_for_tests:0  - Disables the housekeeping loop for local storage. The property exists to simplify testing and shouldn't be set in production.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.log_message_timestamp_alert_after_ms:7200000  - Threshold in milliseconds for alerting on messages with a timestamp after the broker's time, meaning they are in the future relative to the broker's clock.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.log_message_timestamp_alert_before_ms:{nullopt}       - Threshold in milliseconds for alerting on messages with a timestamp before the broker's time, meaning they are in the past relative to the broker's clock. null to disable this check
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.log_message_timestamp_type:CreateTime - Default topic messages timestamp type
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.log_retention_ms:604800000    - delete segments older than this - default 1 week
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.log_segment_ms:{1209600000}   - Default log segment lifetime in ms for topics which do not set segment.ms
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.log_segment_ms_max:31536000000        - Upper bound on topic segment.ms: higher values will be clamped to this value
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.log_segment_ms_min:600000     - Lower bound on topic segment.ms: lower values will be clamped to this value
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.log_segment_size:134217728    - Default log segment size in bytes for topics which do not set segment.bytes
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.log_segment_size_jitter_percent:5     - Random variation to the segment size limit used for each partition
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.log_segment_size_max:{nullopt}        - Upper bound on topic segment.bytes: higher values will be clamped to this limit
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.log_segment_size_min:{1}      - Lower bound on topic segment.bytes: lower values will be clamped to this limit
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.lz4_decompress_reusable_buffers_disabled:0    - Disable reusable preallocated buffers for LZ4 decompression
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.max_compacted_log_segment_size:5368709120     - Max compacted segment size after consolidation
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.max_concurrent_producer_ids:18446744073709551615      - Max number of the active sessions (producers). When the threshold is passed Redpanda terminates old sessions. When an idle producer corresponding to the terminated session wakes up and produces - it leads to its batches being rejected with out of order sequence error.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.max_in_flight_pandaproxy_requests_per_shard:500       - Maximum number of in flight HTTP requests permitted in pandaproxy per shard.  Any additional requests above this limit will be rejected with a 429 error
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.max_in_flight_schema_registry_requests_per_shard:500  - Maximum number of in flight HTTP requests permitted in schema registry per shard.  Any additional requests above this limit will be rejected with a 429 error
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.max_kafka_throttle_delay_ms:30000     - Fail-safe maximum throttle delay on kafka requests
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.max_transactions_per_coordinator:18446744073709551615 - Max number of the active txn sessions (producers). When the threshold is passed Redpanda terminates old sessions. When an idle producer corresponding to the terminated session wakes up and produces - it leads to its batches being rejected with invalid producer epoch or invalid_producer_id_mapping (it depends on the txn execution phase).
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.max_version:  - 
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.members_backend_retry_ms:5000 - Time between members backend reconciliation loop retries 
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.memory_abort_on_alloc_failure:1       - If true, the redpanda process will terminate immediately when an allocation cannot be satisfied due to memory exhaustion. If false, an exception is thrown instead.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.memory_enable_memory_sampling:1       - If true, memory allocations will be sampled and tracked. A sampled live set of allocations can then be retrieved from the Admin API. Additionally, we will periodically log the top-n allocation sites
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.metadata_dissemination_interval_ms:3000       - Interval for metadata dissemination batching
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.metadata_dissemination_retries:30     - Number of attempts of looking up a topic's meta data like shard before failing a request
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.metadata_dissemination_retry_delay_ms:320     - Delay before retry a topic lookup in a shard or other meta tables
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.metadata_status_wait_timeout_ms:2000  - Maximum time to wait in metadata request for cluster health to be refreshed
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.metrics_reporter_report_interval:86400000     - cluster metrics reporter report interval
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.metrics_reporter_tick_interval:60000  - Cluster metrics reporter tick interval
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.metrics_reporter_url:https://m.rp.vectorized.io/v2    - cluster metrics reporter url
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.min_version:  - 
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.minimum_topic_replications:1  - Minimum permitted value of replication factor for new topics
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.node_isolation_heartbeat_timeout:3000 - How long after the last heartbeat request a node will wait before considering itself to be isolated
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.node_management_operation_timeout_ms:5000     - Timeout for executing node management operations
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.node_status_interval:100      - Time interval between two node status messages. Node status messages establish liveness status outside of the Raft protocol.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.node_status_reconnect_max_backoff_ms:15000    - Maximum backoff (in ms) to reconnect to an unresponsive peer during node status liveness checks.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.oidc_clock_skew_tolerance:0   - The amount of seconds to allow for when validating the exp, nbf, and iat claims in the token.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.oidc_discovery_url:https://auth.prd.cloud.redpanda.com/.well-known/openid-configuration - The URL pointing to the well-known discovery endpoint for the OIDC provider.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.oidc_keys_refresh_interval:3600000    - The frequency of refreshing the JSON Web Keys (JWKS) used to validate access tokens.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.oidc_principal_mapping:$.sub  - Rule for mapping JWT Payload claim to a Redpanda User Principal
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.oidc_token_audience:redpanda  - A string representing the intended recipient of the token.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.partition_autobalancing_concurrent_moves:50   - Number of partitions that can be reassigned at once
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.partition_autobalancing_max_disk_usage_percent:80     - Disk usage threshold that triggers moving partitions from the node
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.partition_autobalancing_min_size_threshold:{nullopt}  - Minimum size of partition that is going to be prioritized when rebalancing cluster due to disk size threshold being breached. By default this value is calculated automaticaly
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.partition_autobalancing_mode:node_add - Partition autobalancing mode
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.partition_autobalancing_movement_batch_size_bytes:5368709120  - Total size of partitions that autobalancer is going to move in one batch (deprecated, use partition_autobalancing_concurrent_moves to limit the autobalancer concurrency)
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.partition_autobalancing_node_availability_timeout_sec:900000  - Node unavailability timeout that triggers moving partitions from the node
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.partition_autobalancing_tick_interval_ms:30000        - Partition autobalancer tick interval
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.partition_autobalancing_tick_moves_drop_threshold:0.2 - If the number of scheduled tick moves drops by this ratio, a new tick is scheduled immediately. Valid values are (0, 1]. For example, with a value of 0.2 and 100 scheduled moves in a tick, a new tick is scheduled when the inprogress moves are < 80.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.partition_autobalancing_topic_aware:1 - If true, Redpanda will prioritize balancing topic-wise number of partitions on each node, as opposed to balancing the total number of partitions. This should give better balancing results if topics with diverse partition sizes and load profiles are present in the cluster.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.partition_manager_shutdown_watchdog_timeout:30000     - A threshold value to detect partitions which shutdown might have been stuck. After this threshold a watchdog in partition manager will log information about partition shutdown not making progress
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.pp_sr_smp_max_non_local_requests:{nullopt}    - Maximum number of x-core requests pending in Panda Proxy and Schema Registry seastar::smp group.  (for more details look at `seastar::smp_service_group` documentation)
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.quota_manager_gc_sec:30000    - Quota manager GC frequency in milliseconds
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.raft_enable_longest_log_detection:1   - Enables additional step in leader election where candidate is allowed to wait for all the replies from node it requested votes from. This may introduce a small delay when recovering from failure but will prevent truncation if any of the replicas has more data than the majority.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.raft_enable_lw_heartbeat:1    - enables raft optimization of heartbeats
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.raft_flush_timer_interval_ms:100      - Interval of checking partition against the `raft_replica_max_pending_flush_bytes`, deprecated started 24.1, use raft_replica_max_flush_delay_ms instead 
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.raft_heartbeat_disconnect_failures:3  - After how many failed heartbeats to forcibly close an unresponsive TCP connection.  Set to 0 to disable force disconnection.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.raft_heartbeat_interval_ms:150        - Milliseconds for raft leader heartbeats
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.raft_heartbeat_timeout_ms:3000        - raft heartbeat RPC timeout
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.raft_io_timeout_ms:10000      - Raft I/O timeout
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.raft_learner_recovery_rate:104857600  - Raft learner recovery rate limit in bytes per sec
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.raft_max_concurrent_append_requests_per_follower:16   - Maximum number of concurrent append entries requests sent by leader to one follower
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.raft_max_recovery_memory:{nullopt}    - Max memory that can be used for reads in raft recovery process by default 15% of total memory
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.raft_recovery_concurrency_per_shard:64        - How many partitions may simultaneously recover data to a particular shard. This is limited to avoid overwhelming nodes when they come back online after an outage.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.raft_recovery_default_read_size:524288        - default size of read issued during raft follower recovery
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.raft_recovery_throttle_disable_dynamic_mode:0 - Disables dynamic rate allocation in recovery throttle (advanced).
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.raft_replica_max_flush_delay_ms:100   - Maximum delay (in ms) between two subsequent flushes. After this delay, the log will be automatically force flushed.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.raft_replica_max_pending_flush_bytes:{262144} - Max not flushed bytes per partition. If configured threshold is reached log will automatically be flushed even though it wasn't explicitly requested
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.raft_replicate_batch_window_size:1048576      - Max size of requests cached for replication
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.raft_smp_max_non_local_requests:{nullopt}     - Maximum number of x-core requests pending in Raft seastar::smp group. (for more details look at `seastar::smp_service_group` documentation)
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.raft_timeout_now_timeout_ms:1000      - Timeout for a timeout now request
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.raft_transfer_leader_recovery_timeout_ms:10000        - Timeout waiting for follower recovery when transferring leadership
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.readers_cache_eviction_timeout_ms:30000       - Duration after which inactive readers will be evicted from cache
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.readers_cache_target_max_size:200     - Maximum desired number of readers cached per ntp. This a soft limit, a number of readers in cache may temporary increase as cleanup is done in background
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.reclaim_batch_cache_min_free:67108864 - Free memory limit that will be kept by batch cache background reclaimer
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.reclaim_growth_window:3000    - Length of time in which reclaim sizes grow
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.reclaim_max_size:4194304      - Maximum batch cache reclaim size
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.reclaim_min_size:131072       - Minimum batch cache reclaim size
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.reclaim_stable_window:10000   - Length of time above which growth is reset
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.recovery_append_timeout_ms:5000       - Timeout for append entries requests issued while updating stale follower
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.release_cache_on_segment_roll:0       - Free cache when segments roll
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.replicate_append_timeout_ms:3000      - Timeout for append entries requests issued while replicating entries
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.retention_bytes:{nullopt}     - Default max bytes per partition on disk before triggering a compaction
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.retention_local_strict:0      - Trim log data when a cloud topic reaches its local retention limit. When this option is disabled Redpanda will allow partitions to grow past the local retention limit, and will be trimmed automatically as storage reaches the configured target size.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.retention_local_strict_override:1     - Trim log data when a cloud topic reaches its local retention limit. When this option is disabled Redpanda will allow partitions to grow past the local retention limit, and will be trimmed automatically as storage reaches the configured target size.
INFO  2024-10-25 20:02:36,250 [shard 0:main] main - application.cc:808 - redpanda.retention_local_target_bytes_default:{nullopt}        - Local retention size target for partitions of topics with cloud storage write enabled
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.retention_local_target_capacity_bytes:{nullopt}       - The target capacity in bytes that log storage will try to use before additional retention rules will take over to trim data in order to meet the target. When no target is specified storage usage is unbounded.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.retention_local_target_capacity_percent:{80}  - The target capacity in percent of unreserved space (see disk_reservation_percent) that log storage will try to use before additional retention rules will take over to trim data in order to meet the target. When no target is specified storage usage is unbounded.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.retention_local_target_ms_default:86400000    - Local retention time target for partitions of topics with cloud storage write enabled
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.retention_local_trim_interval:30000   - The maximum amount of time before log storage will examine usage to determine of the target capacity has been exceeded and additional data trimming is required.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.retention_local_trim_overage_coeff:2  - The space management control loop will reclaim the overage multiplied by this this coefficient in order to compensate for data that is written during the idle period between control loop invocations.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.rm_sync_timeout_ms:10000      - Time to wait state catch up before rejecting a request
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.rm_violation_recovery_policy: - 
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.rpc_client_connections_per_peer:32    - The maximum number of connections a broker will open to each of its peers
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.rpc_server_compress_replies:0 - Enable compression for internal rpc server replies
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.rpc_server_listen_backlog:{nullopt}   - TCP connection queue length for Kafka server and internal RPC server
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.rpc_server_tcp_recv_buf:{nullopt}     - Internal RPC TCP receive buffer size in bytes.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.rpc_server_tcp_send_buf:{nullopt}     - Internal RPC TCP transmit buffer size in bytes.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.rps_limit_acls_and_users_operations:1000      - Rate limit for controller acls and users operations
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.rps_limit_configuration_operations:1000       - Rate limit for controller configuration operations
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.rps_limit_move_operations:1000        - Rate limit for controller move operations
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.rps_limit_node_management_operations:1000     - Rate limit for controller node management operations
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.rps_limit_topic_operations:1000       - Rate limit for controller topic operations
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.sasl_kerberos_config:/etc/krb5.conf   - The location of the Kerberos krb5.conf file for Redpanda
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.sasl_kerberos_keytab:/var/lib/redpanda/redpanda.keytab        - The location of the Kerberos keytab file for Redpanda
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.sasl_kerberos_principal:redpanda      - The primary of the Kerberos Service Principal Name (SPN) for Redpanda
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.sasl_kerberos_principal_mapping:{DEFAULT}     - Rules for mapping Kerberos Principal Names to Redpanda User Principals
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.sasl_mechanisms:{SCRAM}       - A list of supported SASL mechanisms. `SCRAM`, `GSSAPI`, and `OAUTHBEARER` are allowed.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.schema_registry_normalize_on_startup:0        - Normalize schemas as they are read from the topic on startup.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.seed_server_meta_topic_partitions:    - 
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.segment_appender_flush_timeout_ms:1000        - Maximum delay until buffered data is written
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.segment_fallocation_step:33554432     - Size for segments fallocation
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.seq_table_min_size:   - 
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.space_management_enable:1     - Enable automatic space management.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.space_management_enable_override:0    - Enable automatic space management. This option is ignored and deprecated in versions >= v23.3.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.space_management_max_log_concurrency:20       - Maximum parallel logs inspected during space management process.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.space_management_max_segment_concurrency:10   - Maximum parallel segments inspected during space management process.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.storage_compaction_index_memory:134217728     - Maximum number of bytes that may be used on each shard by compactionindex writers
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.storage_compaction_key_map_memory:134217728   - Maximum number of bytes that may be used on each shard by compaction key-offset maps. Only respected when `log_compaction_use_sliding_window` is true.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.storage_compaction_key_map_memory_limit_percent:12    - Limit on `storage_compaction_key_map_memory`, expressed as a percentage of memory per shard, that bounds the amount of memory used by compaction key-offset maps. NOTE: Memory per shard is computed after `wasm_per_core_memory_reservation`. Only respected when `log_compaction_use_sliding_window` is true.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.storage_ignore_cstore_hints:0 - if set, cstore hints will be ignored and will not be used for data access (but will otherwise be generated)
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.storage_ignore_timestamps_in_future_sec:{nullopt}     - If set, timestamps more than this many seconds in the future relative tothe server's clock will be ignored for data retention purposes, and retention will act based on another timestamp in the same segment, or the mtime of the segment file if no valid timestamp is available
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.storage_max_concurrent_replay:1024    - Maximum number of partitions' logs that will be replayed concurrently at startup, or flushed concurrently on shutdown.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.storage_min_free_bytes:10485760       - Threshold of minimum bytes free space before rejecting producers.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.storage_read_buffer_size:131072       - Size of each read buffer (one per in-flight read, per log segment)
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.storage_read_readahead_count:10       - How many additional reads to issue ahead of current read location
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.storage_reserve_min_segments:2        - The number of segments per partition that the system will attempt to reserve disk capacity for. For example, if the maximum segment size is configured to be 100 MB, and the value of this option is 2, then in a system with 10 partitions Redpanda will attempt to reserve at least 2 GB of disk space.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.storage_space_alert_free_threshold_bytes:0    - Threshold of minimum bytes free space before setting storage space alert
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.storage_space_alert_free_threshold_percent:5  - Threshold of minimum percent free space before setting storage space alert
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.storage_strict_data_init:0    - Requires that an empty file named `.redpanda_data_dir` be present in the data directory. Redpanda will refuse to start if it is not found.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.storage_target_replay_bytes:10737418240       - Target bytes to replay from disk on startup after clean shutdown: controls frequency of snapshots and checkpoints
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.superusers:{} - List of superuser usernames
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.target_fetch_quota_byte_rate:{nullopt}        - Target fetch size quota byte rate (bytes per second) - disabled default
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.target_quota_byte_rate:0      - Target request size quota byte rate (bytes per second)
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.tls_min_version:v1.2  - The minimum TLS version that Redpanda supports.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.tm_sync_timeout_ms:10000      - Time to wait state catch up before rejecting a request
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.tm_violation_recovery_policy: - 
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.topic_fds_per_partition:{5}   - Required file handles per partition when creating topics
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.topic_memory_per_partition:{4194304}  - Required memory per partition when creating topics
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.topic_partitions_per_shard:1000       - Maximum number of partitions which may be allocated to one shard (CPU core)
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.topic_partitions_reserve_shard0:2     - Reserved partition slots on shard (CPU core) 0 on each node.  If this is >= topic_partitions_per_core, no data partitions will be scheduled on shard 0
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.transaction_coordinator_cleanup_policy:delete - Cleanup policy for a transaction coordinator topic
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.transaction_coordinator_delete_retention_ms:604800000 - delete segments older than this - default 1 week
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.transaction_coordinator_log_segment_size:1073741824   - How large in bytes should each log segment be (default 1G)
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.transaction_coordinator_partitions:50 - Amount of partitions for transactions coordinator
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.transaction_coordinator_replication:  - 
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.transactional_id_expiration_ms:604800000      - Producer ids are expired once this time has elapsed after the last write with the given producer id.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.tx_log_stats_interval_s:10000 - How often to log per partition tx stats, works only with debug logging enabled.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.tx_registry_log_capacity:     - 
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.tx_registry_sync_timeout_ms:  - 
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.tx_timeout_delay_ms:1000      - Delay before scheduling next check for timed out transactions
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.unsafe_enable_consumer_offsets_delete_retention:0     - Enables delete retention of consumer offsets topic. This is an internal-only configuration and should be enabled only after consulting with Redpanda Support or engineers.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.usage_disk_persistance_interval_sec:300000    - The interval in which all usage stats are written to disk
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.usage_num_windows:24  - The number of windows to persist in memory and disk
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.usage_window_width_interval_sec:3600000       - The width of a usage window, tracking cloud and kafka ingress/egress traffic each interval
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.use_fetch_scheduler_group:1   - Use a separate scheduler group for fetch processing
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.use_scheduling_groups:        - 
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.virtual_cluster_min_producer_ids:18446744073709551615 - Minimum number of active producers per virtual cluster
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.wait_for_leader_timeout_ms:5000       - Timeout (ms) to wait for leadership in metadata cache
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.write_caching_default:true    - Cache batches until the segment appender chunk is full instead of flushing for every acks=all write. This is the global default for all topics and can be overriden at a topic scope with property write.caching. 'disabled' mode takes precedence over topic overrides and disables the feature altogether for the entire cluster.
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:808 - redpanda.zstd_decompress_workspace_bytes:8388608       - Size of the zstd decompression workspace
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:859 - Node configuration properties:
INFO  2024-10-25 20:02:36,251 [shard 0:main] main - application.cc:860 - (use `rpk redpanda config set <cfg> <value>` to change)
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.admin:{{:{host: 0.0.0.0, port: 9644}}}        - Address and port of admin server
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.admin_api_doc_dir:/usr/share/redpanda/admin-api-doc   - Admin API doc directory
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.admin_api_tls:{}      - TLS configuration for admin HTTP server
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.advertised_kafka_api:{{PLAINTEXT:{host: localhost, port: 9092}}}- Address of Kafka API published to the clients
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.advertised_rpc_api:{{host: 127.0.0.1, port: 33145}}   - Address of RPC endpoint published to other cluster members
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.cloud_storage_cache_directory:{nullopt}       - Directory for archival cache. Should be present when `cloud_storage_enabled` is present
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.coproc_supervisor_server:     - 
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.crash_loop_limit:{5}  - Maximum consecutive crashes (unclean shutdowns) allowed after which operator intervention is needed to startup the broker. Limit is not enforced in developer mode.
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.dashboard_dir:        - 
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.data_directory:{data_directory="/var/lib/redpanda/data"}      - Place where redpanda will keep the data
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.developer_mode:1      - Skips most of the checks performed at startup, not recomended for production use
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.emergency_disable_data_transforms:0   - Override the cluster enablement setting and disable WebAssembly powered data transforms. Only used as an emergency shutoff button.
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.empty_seed_starts_cluster:1   - If true, an empty seed_servers list will denote that this node should form a cluster. At most one node in the cluster should be configured configured with an empty seed_servers list. If no such configured node exists, or if configured to false, all nodes denoted by the seed_servers list must be identical among those nodes' configurations, and those nodes will form the initial cluster.
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.enable_central_config:        - 
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.fips_mode:disabled    - Controls whether Redpanda starts in FIPS mode.  This property allows for three values: 'disabled', 'enabled', and 'permissive'.  With 'enabled', Redpanda first verifies that the operating system is enabled for FIPS by checking /proc/sys/crypto/fips_enabled.  If the file does not exist or does not return '1', Redpanda immediately exits.  With 'permissive', the same check is performed but a WARNING is logged and Redpanda continues to run.  After the check is complete, Redpanda loads the OpenSSL FIPS provider into the OpenSSL library.  After this is complete, Redpanda is operating in FIPS mode, which means that the TLS cipher suites available to users are limited to TLSv1.2 and TLSv1.3, and of those, only the ones that use NIST-approved cryptographic methods.  For more information about FIPS, refer to Redpanda documentation.
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.kafka_api:{{PLAINTEXT:{host: 0.0.0.0, port: 9092}:{nullopt}}} - Address and port of an interface to listen for Kafka API requests
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.kafka_api_tls:{}      - TLS configuration for Kafka API endpoint
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.memory_allocation_warning_threshold:{131073}  - Enables log messages for allocations greater than the given size.
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.node_id:{0}   - Unique id identifying a node in the cluster. If missing, a unique id will be assigned for this node when it joins the cluster
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.node_id_overrides:{}  - List of node ID and UUID overrides to be applied at broker startup. Each entry includes the current UUID and desired ID and UUID. Each entry applies to a given node if and only if 'current' matches that node's current UUID.
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.openssl_config_file:{nullopt} - Path to the configuration file used by OpenSSL to propertly load the FIPS-compliant module.
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.openssl_module_directory:{nullopt}    - Path to the directory that contains the OpenSSL FIPS-compliant module.
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.rack:{nullopt}        - Rack identifier
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.recovery_mode_enabled:0       - If true, start redpanda in "metadata only" mode, skipping loading user partitions and allowing only metadata operations.
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.rpc_server:{host: 0.0.0.0, port: 33145}       - IpAddress and port for RPC server
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.rpc_server_tls:{ enabled: 0 key/cert files: {nullopt} ca file: {nullopt} crl file: {nullopt} client_auth_required: 0 }  - TLS configuration for RPC server
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.seed_servers:{}       - List of the seed servers used to join current cluster. If the seed_server list is empty the node will be a cluster root and it will form a new cluster
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.storage_failure_injection_config_path:{nullopt}       - Path to the configuration file used for low level storage failure injection
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.storage_failure_injection_enabled:0   - If true, inject low level storage failures on the write path. **Not** for production usage.
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.upgrade_override_checks:0     - Whether to violate safety checks when starting a redpanda version newer than the cluster's consensus version
INFO  2024-10-25 20:02:36,252 [shard 0:main] main - application.cc:808 - redpanda.verbose_logging_timeout_sec_max:{nullopt}     - Maximum duration in seconds for verbose (i.e. TRACE or DEBUG) logging. Values configured above this will be clamped. If null (the default) there is no limit. Can be overridded in the Admin API on a per-request basis.
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy.advertised_pandaproxy_api:{}        - Rest API address and port to publish to client
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy.api_doc_dir:/usr/share/redpanda/proxy-api-doc       - API doc directory
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy.client_cache_max_size:10    - The maximum number of kafka clients in the LRU cache
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy.client_keep_alive:300000    - Time in milliseconds that an idle connection may remain open
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy.consumer_instance_timeout_ms:300000 - How long to wait for an idle consumer before removing it
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy.pandaproxy_api:{{:{host: 0.0.0.0, port: 8082}:<nullopt>}}   - Rest API listen address and port
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy.pandaproxy_api_tls:{}       - TLS configuration for Pandaproxy api
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy_client.broker_tls:{ enabled: 0 key/cert files: {nullopt} ca file: {nullopt} crl file: {nullopt} client_auth_required: 0 }     - TLS configuration for the brokers
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy_client.brokers:{{host: 0.0.0.0, port: 9092}}        - List of address and port of the brokers
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy_client.client_identifier:{pandaproxy_client}        - Identifier to use within the kafka request header
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy_client.consumer_heartbeat_interval_ms:500   - Interval (in milliseconds) for consumer heartbeats
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy_client.consumer_rebalance_timeout_ms:2000   - Timeout (in milliseconds) for consumer rebalance
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy_client.consumer_request_max_bytes:1048576   - Max bytes to fetch per request
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy_client.consumer_request_min_bytes:1 - Min bytes to fetch per request
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy_client.consumer_request_timeout_ms:100      - Interval (in milliseconds) for consumer request timeout
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy_client.consumer_session_timeout_ms:300000   - Timeout (in milliseconds) for consumer session
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy_client.produce_ack_level:-1 - Number of acknowledgments the producer requires the leader to have received before considering a request complete, choices are 0, 1 and -1
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy_client.produce_batch_delay_ms:100   - Delay (in milliseconds) to wait before sending batch
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy_client.produce_batch_record_count:1000      - Number of records to batch before sending to broker
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy_client.produce_batch_size_bytes:1048576     - Number of bytes to batch before sending to broker
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy_client.produce_compression_type:none        - Enable or disable compression by the kafka client. Specify 'none' to disable compression or one of the supported types [gzip, snappy, lz4, zstd]
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy_client.produce_shutdown_delay_ms:0  - Delay (in milliseconds) to allow for final flush of buffers before shutting down
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy_client.retries:5    - Number of times to retry a request to a broker
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy_client.retry_base_backoff_ms:100    - Delay (in milliseconds) for initial retry backoff
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy_client.sasl_mechanism:      - The SASL mechanism to use when connecting
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy_client.scram_password:      - Password to use for SCRAM authentication mechanisms
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - pandaproxy_client.scram_username:      - Username to use for SCRAM authentication mechanisms
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry.api_doc_dir:/usr/share/redpanda/proxy-api-doc  - API doc directory
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry.mode_mutability:1      - Allow modifying mode
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry.schema_registry_api:{{:{host: 0.0.0.0, port: 8081}:<nullopt>}}   - Schema Registry API listen address and port
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry.schema_registry_api_tls:{}     - TLS configuration for Schema Registry API
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry.schema_registry_replication_factor:{nullopt}   - Replication factor for internal _schemas topic.  If unset, defaults to `default_topic_replication`
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry_client.broker_tls:{ enabled: 0 key/cert files: {nullopt} ca file: {nullopt} crl file: {nullopt} client_auth_required: 0 }        - TLS configuration for the brokers
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry_client.brokers:{{host: 0.0.0.0, port: 9092}}   - List of address and port of the brokers
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry_client.client_identifier:{schema_registry_client}      - Identifier to use within the kafka request header
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry_client.consumer_heartbeat_interval_ms:500      - Interval (in milliseconds) for consumer heartbeats
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry_client.consumer_rebalance_timeout_ms:2000      - Timeout (in milliseconds) for consumer rebalance
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry_client.consumer_request_max_bytes:1048576      - Max bytes to fetch per request
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry_client.consumer_request_min_bytes:1    - Min bytes to fetch per request
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry_client.consumer_request_timeout_ms:100 - Interval (in milliseconds) for consumer request timeout
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry_client.consumer_session_timeout_ms:10000       - Timeout (in milliseconds) for consumer session
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry_client.produce_ack_level:-1    - Number of acknowledgments the producer requires the leader to have received before considering a request complete, choices are 0, 1 and -1
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry_client.produce_batch_delay_ms:0        - Delay (in milliseconds) to wait before sending batch
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry_client.produce_batch_record_count:0    - Number of records to batch before sending to broker
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry_client.produce_batch_size_bytes:0      - Number of bytes to batch before sending to broker
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry_client.produce_compression_type:none   - Enable or disable compression by the kafka client. Specify 'none' to disable compression or one of the supported types [gzip, snappy, lz4, zstd]
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry_client.produce_shutdown_delay_ms:0     - Delay (in milliseconds) to allow for final flush of buffers before shutting down
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry_client.retries:5       - Number of times to retry a request to a broker
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry_client.retry_base_backoff_ms:100       - Delay (in milliseconds) for initial retry backoff
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry_client.sasl_mechanism: - The SASL mechanism to use when connecting
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry_client.scram_password: - Password to use for SCRAM authentication mechanisms
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - schema_registry_client.scram_username: - Username to use for SCRAM authentication mechanisms
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - audit_log_client.broker_tls:{ enabled: 0 key/cert files: {nullopt} ca file: {nullopt} crl file: {nullopt} client_auth_required: 0 }      - TLS configuration for the brokers
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - audit_log_client.brokers:{{host: 0.0.0.0, port: 9092}} - List of address and port of the brokers
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - audit_log_client.client_identifier:{audit_log_client}  - Identifier to use within the kafka request header
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - audit_log_client.consumer_heartbeat_interval_ms:500    - Interval (in milliseconds) for consumer heartbeats
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - audit_log_client.consumer_rebalance_timeout_ms:2000    - Timeout (in milliseconds) for consumer rebalance
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - audit_log_client.consumer_request_max_bytes:1048576    - Max bytes to fetch per request
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - audit_log_client.consumer_request_min_bytes:1  - Min bytes to fetch per request
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - audit_log_client.consumer_request_timeout_ms:100       - Interval (in milliseconds) for consumer request timeout
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - audit_log_client.consumer_session_timeout_ms:10000     - Timeout (in milliseconds) for consumer session
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - audit_log_client.produce_ack_level:1   - Number of acknowledgments the producer requires the leader to have received before considering a request complete, choices are 0, 1 and -1
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - audit_log_client.produce_batch_delay_ms:0      - Delay (in milliseconds) to wait before sending batch
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - audit_log_client.produce_batch_record_count:0  - Number of records to batch before sending to broker
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - audit_log_client.produce_batch_size_bytes:0    - Number of bytes to batch before sending to broker
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - audit_log_client.produce_compression_type:zstd - Enable or disable compression by the kafka client. Specify 'none' to disable compression or one of the supported types [gzip, snappy, lz4, zstd]
INFO  2024-10-25 20:02:36,253 [shard 0:main] main - application.cc:808 - audit_log_client.produce_shutdown_delay_ms:3000        - Delay (in milliseconds) to allow for final flush of buffers before shutting down
INFO  2024-10-25 20:02:36,254 [shard 0:main] main - application.cc:808 - audit_log_client.retries:5     - Number of times to retry a request to a broker
INFO  2024-10-25 20:02:36,254 [shard 0:main] main - application.cc:808 - audit_log_client.retry_base_backoff_ms:100     - Delay (in milliseconds) for initial retry backoff
INFO  2024-10-25 20:02:36,254 [shard 0:main] main - application.cc:808 - audit_log_client.sasl_mechanism:       - The SASL mechanism to use when connecting
INFO  2024-10-25 20:02:36,254 [shard 0:main] main - application.cc:808 - audit_log_client.scram_password:       - Password to use for SCRAM authentication mechanisms
INFO  2024-10-25 20:02:36,254 [shard 0:main] main - application.cc:808 - audit_log_client.scram_username:       - Username to use for SCRAM authentication mechanisms
INFO  2024-10-25 20:02:36,256 [shard 0:main] seastar - Enabling heap profiler - using 3000037 bytes sampling rate
INFO  2024-10-25 20:02:36,256 [shard 0:main] main - application.cc:523 - Setting abort_on_allocation_failure (abort on OOM): true
INFO  2024-10-25 20:02:36,269 [shard 0:main] syschecks - Writing pid file "/var/lib/redpanda/data/pid.lock"
INFO  2024-10-25 20:02:36,276 [shard 0:main] storage - directories.h:33 - Checking `/var/lib/redpanda/data` for supported filesystems
INFO  2024-10-25 20:02:36,277 [shard 0:main] syschecks - Detected file system type is ext2
WARN  2024-10-25 20:02:36,277 [shard 0:main] syschecks - Path: `/var/lib/redpanda/data' is on ext4, not XFS. This will probably work, but Redpanda is only tested on XFS and XFS is recommended for best performance.
INFO  2024-10-25 20:02:36,278 [shard 0:main] cloud_storage - cache_service.cc:1920 - Creating cache directory "/var/lib/redpanda/data/cloud_storage_cache"
INFO  2024-10-25 20:02:36,286 [shard 0:main] ossl-library-context-service - ossl_context_service.cc:254 - OpenSSL Context loaded and ready
INFO  2024-10-25 20:02:36,444 [shard 0:main] rpc - server.cc:41 - Creating net::server for internal_rpc with config {{://0.0.0.0:33145:PLAINTEXT}, max_service_memory_per_core: 188978560, metrics_enabled:true, listen_backlog:{nullopt}, tcp_recv_buf:{nullopt}, tcp_send_buf:{nullopt}, stream_recv_buf:{nullopt}}
INFO  2024-10-25 20:02:36,456 [shard 0:main] features - feature_table.cc:434 - Activating features from bootstrap version 7
INFO  2024-10-25 20:02:36,456 [shard 0:main] main - application.cc:2456 - Generated new UUID for node: 244ae0e7-a67c-4936-b802-2bb7aabf3092
INFO  2024-10-25 20:02:36,468 [shard 0:main] storage - segment.cc:811 - Creating new segment /var/lib/redpanda/data/redpanda/kvstore/0_0/0-0-v1.log
INFO  2024-10-25 20:02:36,478 [shard 0:main] main - application.cc:2505 - Started RPC server listening at {host: 0.0.0.0, port: 33145}
INFO  2024-10-25 20:02:36,480 [shard 0:main] main - application.cc:2611 - Starting Redpanda with node_id 0, cluster UUID {nullopt}
INFO  2024-10-25 20:02:36,482 [shard 0:main] raft - coordinated_recovery_throttle.cc:126 - Starting recovery throttle, rate: 104857600
INFO  2024-10-25 20:02:36,482 [shard 0:main] cluster - producer_state_manager.cc:45 - Started producer state manager
INFO  2024-10-25 20:02:36,482 [shard 0:main] main - application.cc:1583 - Partition manager started
INFO  2024-10-25 20:02:36,488 [shard 0:main] main - application.cc:1671 - Archiver service setup, cloud_storage_enabled: false, legacy_upload_mode_enabled: true
INFO  2024-10-25 20:02:36,493 [shard 0:main] resource_mgmt - storage.cc:182 - Setting new target log data size 35.020GiB. Disk size 58.367GiB reservation percent 25 target percent {80} bytes {nullopt}
INFO  2024-10-25 20:02:36,496 [shard 0:main] kafka - server.cc:41 - Creating net::server for kafka_rpc with config {{PLAINTEXT://0.0.0.0:9092:PLAINTEXT}, max_service_memory_per_core: 283467840, metrics_enabled:true, listen_backlog:{nullopt}, tcp_recv_buf:{nullopt}, tcp_send_buf:{nullopt}, stream_recv_buf:{nullopt}}
INFO  2024-10-25 20:02:36,522 [shard 0:main] cluster - controller.cc:1154 - persisted initial configuration invariants: { version: 0, node_id: 0, core_count: 1 }
INFO  2024-10-25 20:02:36,523 [shard 0:main] cluster - raft0_utils.h:30 - Current node is a cluster founder
INFO  2024-10-25 20:02:36,561 [shard 0:main] raft - [group_id:0, {redpanda/controller/0}] consensus.cc:1403 - Starting with voted_for {id: -2147483648, revision: -9223372036854775808} term 0 initial_state true
INFO  2024-10-25 20:02:36,586 [shard 0:main] raft - [group_id:0, {redpanda/controller/0}] consensus.cc:1447 - Current log offsets: {start_offset:-9223372036854775808, committed_offset:-9223372036854775808, committed_offset_term:-9223372036854775808, dirty_offset:-9223372036854775808, dirty_offset_term:-9223372036854775808}, read bootstrap state: data_seen 0 config_seen 0 eol false commit 0 term 0 prev_idx 0 prev_term 0 config_tracker -9223372036854775808 commit_base_tracker -9223372036854775808 configurations {}
INFO  2024-10-25 20:02:36,586 [shard 0:main] raft - [group_id:0, {redpanda/controller/0}] consensus.cc:1469 - Truncating configurations at -9223372036854775808
INFO  2024-10-25 20:02:36,610 [shard 0:main] raft - [group_id:0, {redpanda/controller/0}] consensus.cc:934 - starting pre-vote leader election, current term: 0, leadership transfer: false
INFO  2024-10-25 20:02:36,621 [shard 0:main] raft - [group_id:0, {redpanda/controller/0}] consensus.cc:1580 - started raft, log offsets: {start_offset:-9223372036854775808, committed_offset:-9223372036854775808, committed_offset_term:-9223372036854775808, dirty_offset:-9223372036854775808, dirty_offset_term:-9223372036854775808}, term: 0, configuration: {current: {voters: {{id: 0, revision: 0}}, learners: {}}, old:{nullopt}, revision: 0, update: {nullopt}, version: 4}, brokers: {{id: 0, kafka_advertised_listeners: {{PLAINTEXT:{host: localhost, port: 9092}}}, rpc_address: {host: 127.0.0.1, port: 33145}, rack: {nullopt}, properties: {cores 1, mem_available 1073741824, disk_available 58, in_fips_mode disabled}}}}
INFO  2024-10-25 20:02:36,630 [shard 0:main] cluster - drain_manager.cc:21 - Drain manager starting
INFO  2024-10-25 20:02:36,631 [shard 0:main] cluster - members_manager.cc:98 - starting  members manager with founding brokers: {{id: 0, kafka_advertised_listeners: {{PLAINTEXT:{host: localhost, port: 9092}}}, rpc_address: {host: 127.0.0.1, port: 33145}, rack: {nullopt}, properties: {cores 1, mem_available 1073741824, disk_available 58, in_fips_mode disabled}}}
INFO  2024-10-25 20:02:36,631 [shard 0:main] cluster - controller.cc:550 - Controller log replay starting (to offset -9223372036854775808)
INFO  2024-10-25 20:02:36,631 [shard 0:main] cluster - controller.cc:561 - Controller log replay complete.
INFO  2024-10-25 20:02:36,638 [shard 0:main] raft - [group_id:0, {redpanda/controller/0}] vote_stm.cc:418 - becoming the leader term:1
INFO  2024-10-25 20:02:36,640 [shard 0:main] storage - segment.cc:811 - Creating new segment /var/lib/redpanda/data/redpanda/controller/0_0/0-1-v1.log
INFO  2024-10-25 20:02:36,668 [shard 0:main] cluster - members_manager.cc:208 - processing raft-0 configuration at offset: 0 with brokers: [{id: 0, kafka_advertised_listeners: {{PLAINTEXT:{host: localhost, port: 9092}}}, rpc_address: {host: 127.0.0.1, port: 33145}, rack: {nullopt}, properties: {cores 1, mem_available 0, disk_available 58, in_fips_mode disabled}}]
INFO  2024-10-25 20:02:36,668 [shard 0:main] cluster - members_table.cc:82 - applying node add command for: {id: 0, kafka_advertised_listeners: {{PLAINTEXT:{host: localhost, port: 9092}}}, rpc_address: {host: 127.0.0.1, port: 33145}, rack: {nullopt}, properties: {cores 1, mem_available 0, disk_available 58, in_fips_mode disabled}}
INFO  2024-10-25 20:02:36,669 [shard 0:main] raft - [group_id:0, {redpanda/controller/0}] vote_stm.cc:433 - became the leader term: 1
INFO  2024-10-25 20:02:36,732 [shard 0:main] cluster - controller.cc:950 - Creating cluster UUID 8d8ca896-5853-4bdb-ae36-4512a1ac609f
INFO  2024-10-25 20:02:36,735 [shard 0:main] cluster - bootstrap_backend.cc:92 - Applying update to bootstrap_manager
INFO  2024-10-25 20:02:36,736 [shard 0:main] cluster - members_manager.cc:847 - Initial node UUID map: {244ae0e7-a67c-4936-b802-2bb7aabf3092: 0}
INFO  2024-10-25 20:02:36,736 [shard 0:main] cluster - members_table.cc:98 - setting initial nodes {{id: 0, kafka_advertised_listeners: {{PLAINTEXT:{host: localhost, port: 9092}}}, rpc_address: {host: 127.0.0.1, port: 33145}, rack: {nullopt}, properties: {cores 1, mem_available 1073741824, disk_available 58, in_fips_mode disabled}}}
INFO  2024-10-25 20:02:36,748 [shard 0:main] features - feature_table.cc:434 - Activating features from bootstrap version 13
INFO  2024-10-25 20:02:36,749 [shard 0:main] cluster - feature_backend.cc:149 - Saving feature_table_snapshot at version 13...
INFO  2024-10-25 20:02:36,772 [shard 0:main] cluster - controller.cc:958 - Cluster UUID created 8d8ca896-5853-4bdb-ae36-4512a1ac609f
INFO  2024-10-25 20:02:36,777 [shard 0:main] cluster - controller_backend.cc:813 - Cleaning up orphan topic files. bootstrap_revision: -9223372036854775808
INFO  2024-10-25 20:02:36,778 [shard 0:main] cluster - feature_manager.cc:92 - Starting...
INFO  2024-10-25 20:02:36,778 [shard 0:main] cluster - feature_manager.cc:531 - Activating features after upgrade...
INFO  2024-10-25 20:02:36,778 [shard 0:main] cluster - feature_manager.cc:540 - Activating feature broker_time_based_retention (logical version 13)
INFO  2024-10-25 20:02:36,779 [shard 0:main] cluster - metrics_reporter.cc:290 - Waiting to initialize cluster metrics ID...
INFO  2024-10-25 20:02:36,779 [shard 0:main] cluster - partition_balancer_backend.cc:101 - partition balancer started
INFO  2024-10-25 20:02:36,779 [shard 0:main] data-migrate - data_migration_backend.cc:104 - backend starting
INFO  2024-10-25 20:02:36,779 [shard 0:main] data-migrate - data_migration_backend.cc:165 - backend not started as cloud_storage_api is not available
INFO  2024-10-25 20:02:36,781 [shard 0:main] cluster - leader_balancer.cc:104 - Leader balancer: controller leadership detected. Starting rebalancer in 30 seconds
INFO  2024-10-25 20:02:36,792 [shard 0:main] cluster - config_manager.cc:164 - Importing property auto_create_topics_enabled:1
INFO  2024-10-25 20:02:36,792 [shard 0:main] cluster - config_manager.cc:164 - Importing property storage_min_free_bytes:10485760
INFO  2024-10-25 20:02:36,792 [shard 0:main] cluster - config_manager.cc:164 - Importing property group_initial_rebalance_delay:0
INFO  2024-10-25 20:02:36,792 [shard 0:main] cluster - config_manager.cc:164 - Importing property write_caching_default:true
INFO  2024-10-25 20:02:36,792 [shard 0:main] cluster - config_manager.cc:164 - Importing property fetch_reads_debounce_timeout:10
INFO  2024-10-25 20:02:36,792 [shard 0:main] cluster - config_manager.cc:164 - Importing property log_segment_size_min:{1}
INFO  2024-10-25 20:02:36,792 [shard 0:main] cluster - config_manager.cc:164 - Importing property group_topic_partitions:3
WARN  2024-10-25 20:02:36,806 [shard 0:main] admin_api_server - server.cc:539 - Insecure Admin API listener on 0.0.0.0:9644, consider enabling `admin_api_require_auth`
INFO  2024-10-25 20:02:36,806 [shard 0:main] admin_api_server - server.cc:349 - Started HTTP admin service listening at {{:{host: 0.0.0.0, port: 9644}}}
INFO  2024-10-25 20:02:36,806 [shard 0:main] resource_mgmt - storage.cc:73 - Starting disk space manager service (enabled)
INFO  2024-10-25 20:02:36,811 [shard 0:main] cluster - feature_backend.cc:149 - Saving feature_table_snapshot at version 13...
INFO  2024-10-25 20:02:36,811 [shard 0:main] main - application.cc:2652 - Started Pandaproxy listening at {{:{host: 0.0.0.0, port: 8082}:<nullopt>}}
INFO  2024-10-25 20:02:36,815 [shard 0:main] main - application.cc:2660 - Started Schema Registry listening at {{:{host: 0.0.0.0, port: 8081}:<nullopt>}}
INFO  2024-10-25 20:02:36,815 [shard 0:main] main - application.cc:2995 - Waiting for cluster membership
INFO  2024-10-25 20:02:36,815 [shard 0:main] main - application.cc:3013 - Waiting for Cluster ID to initialize...
INFO  2024-10-25 20:02:36,823 [shard 0:main] cluster - metrics_reporter.cc:334 - Generated cluster metrics ID b4bf0fff-ef72-4356-82fb-10fb8a79b11b
INFO  2024-10-25 20:02:36,828 [shard 0:main] cluster - members_manager.cc:441 - applying node update command - broker: {id: 0, kafka_advertised_listeners: {{PLAINTEXT:{host: localhost, port: 9092}}}, rpc_address: {host: 127.0.0.1, port: 33145}, rack: {nullopt}, properties: {cores 1, mem_available 1073741824, disk_available 58, in_fips_mode disabled}}, offset: 4
INFO  2024-10-25 20:02:36,828 [shard 0:main] cluster - members_manager.cc:542 - processing node update command - broker: {id: 0, kafka_advertised_listeners: {{PLAINTEXT:{host: localhost, port: 9092}}}, rpc_address: {host: 127.0.0.1, port: 33145}, rack: {nullopt}, properties: {cores 1, mem_available 1073741824, disk_available 58, in_fips_mode disabled}}, offset: 4
INFO  2024-10-25 20:02:36,828 [shard 0:main] cluster - members_table.cc:111 - applying update node config command for: {id: 0, kafka_advertised_listeners: {{PLAINTEXT:{host: localhost, port: 9092}}}, rpc_address: {host: 127.0.0.1, port: 33145}, rack: {nullopt}, properties: {cores 1, mem_available 1073741824, disk_available 58, in_fips_mode disabled}}
INFO  2024-10-25 20:02:36,829 [shard 0:main] cluster - config_manager.cc:136 - Completed bootstrap as leader
INFO  2024-10-25 20:02:36,829 [shard 0:main] cluster - config_manager.cc:124 - Bootstrap complete (version 1)
INFO  2024-10-25 20:02:36,834 [shard 0:main] cluster - members_manager.cc:164 - Node configuration updated successfully
INFO  2024-10-25 20:02:36,835 [shard 0:main] main - application.cc:3024 - Started Kafka API server listening at {{PLAINTEXT:{host: 0.0.0.0, port: 9092}:{nullopt}}}
INFO  2024-10-25 20:02:36,835 [shard 0:main] main - application.cc:2703 - Successfully started Redpanda!
INFO  2024-10-25 20:02:36,836 [shard 0:main] cluster - metrics_reporter.cc:364 - Initialized cluster_id to b4bf0fff-ef72-4356-82fb-10fb8a79b11b
INFO  2024-10-25 20:02:39,799 [shard 0:main] cluster - partition_balancer_planner.cc:1972 - counts rebalancing objective in domain -1: 1 -> 1
INFO  2024-10-25 20:02:39,799 [shard 0:main] cluster - partition_balancer_planner.cc:1972 - counts rebalancing objective in domain 0: 1 -> 1
INFO  2024-10-25 20:02:39,799 [shard 0:main] cluster - partition_balancer_backend.cc:423 - last status: in_progress; violations: unavailable nodes: 0, full nodes: 0; nodes to rebalance count: 1; on demand rebalance requested: false; updates in progress: 0; action counts: reassignments: 0, cancellations: 0, failed: 0; counts rebalancing finished: true, force refresh health report: false
INFO  2024-10-25 20:02:39,800 [shard 0:main] cluster - members_manager.cc:375 - applying finish_reallocations_cmd, offset: 8, node id: 0
INFO  2024-10-25 20:03:36,790 [shard 0:main] cluster - controller_stm.cc:136 - created snapshot at offset 8 in 14 ms
INFO  2024-10-25 20:03:36,815 [shard 0:main] storage - disk_log_impl.cc:2475 - Removing "/var/lib/redpanda/data/redpanda/controller/0_0/0-1-v1.log" (remove_prefix_full_segments, {offset_tracker:{term:1, base_offset:0, committed_offset:8, dirty_offset:8}, compacted_segment=0, finished_self_compaction=0, finished_windowed_compaction=0, generation=18, reader={/var/lib/redpanda/data/redpanda/controller/0_0/0-1-v1.log, (1572 bytes)}, writer={no_of_chunks:64, closed:0, fallocation_offset:33554432, stable_offset:1572, flushed_offset:1572, committed_offset:1572, inflight:0, dispatched:0, merged:1, bytes_flush_pending:0}, cache={cache_size=9, dirty tracker: {min: -9223372036854775808, max: -9223372036854775808}}, compaction_index:nullopt, closed=0, tombstone=0, index={file:/var/lib/redpanda/data/redpanda/controller/0_0/0-1-v1.base_index, offsets:0, index:{header_bitflags:0, base_offset:0, max_offset:8, base_timestamp:{timestamp: 1729886556638}, max_timestamp:{timestamp: 1729886559800}, batch_timestamps_are_monotonic:1, with_offset:false, non_data_timestamps:0, broker_timestamp:{{timestamp: 1729886559799}}, num_compactible_records_appended:{8}, index(1,1,1)}, step:32768, needs_persistence:1}})
INFO  2024-10-25 20:04:49,595 [shard 0:main] cluster - topics_frontend.cc:151 - Create topics [{configuration: { topic: {kafka/stream_topic}, partition_count: 1, replication_factor: 1, is_migrated: false, properties: {compression: {nullopt}, cleanup_policy_bitflags: {nullopt}, compaction_strategy: {nullopt}, retention_bytes: {}, retention_duration_ms: {}, segment_size: {nullopt}, timestamp_type: {nullopt}, recovery_enabled: {nullopt}, shadow_indexing: {disabled}, read_replica: {nullopt}, read_replica_bucket: {nullopt}, remote_topic_namespace_override: {nullopt}, remote_topic_properties: {nullopt}, batch_max_bytes: {nullopt}, retention_local_target_bytes: {}, retention_local_target_ms: {}, remote_delete: true, segment_ms: {}, record_key_schema_id_validation: {nullopt}, record_key_schema_id_validation_compat: {nullopt}, record_key_subject_name_strategy:  {nullopt}, record_key_subject_name_strategy_compat: {nullopt}, record_value_schema_id_validation: {nullopt},  record_value_schema_id_validation_compat: {nullopt}, record_value_subject_name_strategy: {nullopt}, record_value_subject_name_strategy_compat: {nullopt}, initial_retention_local_target_bytes: {}, initial_retention_local_target_ms: {}, mpx_virtual_cluster_id: {nullopt}, write_caching: {nullopt}, flush_ms: {nullopt}, flush_bytes: {nullopt}, remote_label: {nullopt}}}, custom_assignments: {}},]
INFO  2024-10-25 20:04:49,617 [shard 0:main] storage - segment.cc:811 - Creating new segment /var/lib/redpanda/data/redpanda/controller/0_0/9-1-v1.log
INFO  2024-10-25 20:04:49,675 [shard 0:main] raft - [group_id:1, {kafka/stream_topic/0}] consensus.cc:1403 - Starting with voted_for {id: -2147483648, revision: -9223372036854775808} term 0 initial_state true
INFO  2024-10-25 20:04:49,697 [shard 0:main] offset_translator - ntp: {kafka/stream_topic/0} - offset_translator.cc:120 - resetting offset translation state
INFO  2024-10-25 20:04:49,719 [shard 0:main] offset_translator - ntp: {kafka/stream_topic/0} - offset_translator.cc:166 - started, state: {base offset/delta: -9223372036854775808/0, map size: 1, last delta: 0}, highest_known_offset: -9223372036854775808
INFO  2024-10-25 20:04:49,719 [shard 0:main] raft - [group_id:1, {kafka/stream_topic/0}] consensus.cc:1447 - Current log offsets: {start_offset:-9223372036854775808, committed_offset:-9223372036854775808, committed_offset_term:-9223372036854775808, dirty_offset:-9223372036854775808, dirty_offset_term:-9223372036854775808}, read bootstrap state: data_seen 0 config_seen 0 eol false commit 0 term 0 prev_idx 0 prev_term 0 config_tracker -9223372036854775808 commit_base_tracker -9223372036854775808 configurations {}
INFO  2024-10-25 20:04:49,720 [shard 0:main] raft - [group_id:1, {kafka/stream_topic/0}] consensus.cc:1469 - Truncating configurations at -9223372036854775808
INFO  2024-10-25 20:04:49,742 [shard 0:main] raft - [group_id:1, {kafka/stream_topic/0}] consensus.cc:934 - starting pre-vote leader election, current term: 0, leadership transfer: false
INFO  2024-10-25 20:04:49,765 [shard 0:main] raft - [group_id:1, {kafka/stream_topic/0}] consensus.cc:1580 - started raft, log offsets: {start_offset:-9223372036854775808, committed_offset:-9223372036854775808, committed_offset_term:-9223372036854775808, dirty_offset:-9223372036854775808, dirty_offset_term:-9223372036854775808}, term: 0, configuration: {current: {voters: {{id: 0, revision: 9}}, learners: {}}, old:{nullopt}, revision: 9, update: {nullopt}, version: 5}}
INFO  2024-10-25 20:04:49,776 [shard 0:main] raft - [group_id:1, {kafka/stream_topic/0}] vote_stm.cc:418 - becoming the leader term:1
INFO  2024-10-25 20:04:49,776 [shard 0:main] storage - segment.cc:811 - Creating new segment /var/lib/redpanda/data/kafka/stream_topic/0_9/0-1-v1.log
INFO  2024-10-25 20:04:49,801 [shard 0:main] tx - [{kafka/stream_topic/0}] - rm_stm.cc:109 - Setting bootstrap committed offset to: 0
INFO  2024-10-25 20:04:49,801 [shard 0:main] raft - [group_id:1, {kafka/stream_topic/0}] vote_stm.cc:433 - became the leader term: 1
INFO  2024-10-25 20:04:49,831 [shard 0:main] kafka - create_topics.cc:149 - Created topic(s) {{kafka/stream_topic}} successfully
INFO  2024-10-25 20:05:49,671 [shard 0:main] cluster - controller_stm.cc:136 - created snapshot at offset 9 in 43 ms
INFO  2024-10-25 20:05:49,684 [shard 0:main] storage - disk_log_impl.cc:2475 - Removing "/var/lib/redpanda/data/redpanda/controller/0_0/9-1-v1.log" (remove_prefix_full_segments, {offset_tracker:{term:1, base_offset:9, committed_offset:9, dirty_offset:9}, compacted_segment=0, finished_self_compaction=0, finished_windowed_compaction=0, generation=2, reader={/var/lib/redpanda/data/redpanda/controller/0_0/9-1-v1.log, (240 bytes)}, writer={no_of_chunks:64, closed:0, fallocation_offset:33554432, stable_offset:240, flushed_offset:240, committed_offset:240, inflight:0, dispatched:0, merged:0, bytes_flush_pending:0}, cache={cache_size=1, dirty tracker: {min: -9223372036854775808, max: -9223372036854775808}}, compaction_index:nullopt, closed=0, tombstone=0, index={file:/var/lib/redpanda/data/redpanda/controller/0_0/9-1-v1.base_index, offsets:9, index:{header_bitflags:0, base_offset:9, max_offset:9, base_timestamp:{timestamp: 1729886689617}, max_timestamp:{timestamp: 1729886689617}, batch_timestamps_are_monotonic:1, with_offset:true, non_data_timestamps:0, broker_timestamp:{{timestamp: 1729886689618}}, num_compactible_records_appended:{1}, index(1,1,1)}, step:32768, needs_persistence:1}})